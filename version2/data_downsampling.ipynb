{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset Solely Off of Boredom Labels\n",
    "\n",
    "## Working with a multi-label dataset is too complicated as the data is very unbalanced. So for now, we will only pick 1 label from the dataset, I picked boredom because it is the least unbalanced out of the four labels.\n",
    "\n",
    "Create a new dataset by keeping only the 'Boredom' label column and balancing the classes by reducing all videos to match the size of the smallest class within the 'Boredom' label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import shutil\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced boredom dataset class distribution:\n",
      "(8925, 2)\n",
      "Boredom\n",
      "0    3822\n",
      "1    2850\n",
      "2    1923\n",
      "3     330\n",
      "Name: count, dtype: int64\n",
      "-------------------------------------------s\n",
      "Balanced dataset class distribution:\n",
      "Boredom\n",
      "0    330\n",
      "1    330\n",
      "2    330\n",
      "3    330\n",
      "Name: count, dtype: int64\n",
      "-------------------------------------------\n",
      "{'110001': 10, '110005': 10, '110006': 10, '110007': 10, '110012': 10, '110014': 10, '110015': 10, '110017': 10, '111003': 10, '181374': 10, '200050': 10, '202614': 10, '205601': 10, '210052': 10, '210053': 10, '210055': 10, '210057': 10, '210058': 10, '210059': 10, '210060': 10, '210061': 10, '226051': 10, '240846': 10, '310062': 10, '310070': 10, '310072': 10, '310074': 10, '310075': 10, '310076': 10, '310077': 10, '310078': 10, '310079': 10, '310082': 10, '334463': 10, '342227': 10, '350361': 10, '400018': 10, '400022': 10, '400030': 10, '400033': 10, '410019': 10, '410020': 10, '410024': 10, '410025': 10, '410026': 10, '410028': 10, '410029': 10, '410030': 10, '410032': 10, '411021': 10, '411031': 10, '414081': 10, '459999': 10, '500039': 10, '500044': 10, '500067': 10, '500095': 10, '510034': 10, '510035': 10, '510038': 10, '510040': 10, '510042': 10, '510046': 10, '522129': 10, '556463': 10, '567496': 10, '799402': 10, '826382': 10, '826412': 10, '882654': 10}\n",
      "\n",
      "Length of the updated dataset:\n",
      "700\n",
      "Train set size: 489\n",
      "Validation set size: 140\n",
      "Test set size: 71\n",
      "Train, validation, and test splits saved as CSV files.\n"
     ]
    }
   ],
   "source": [
    "label_set = pd.read_csv(r\"C:\\Users\\ahmad\\Desktop\\EngagementML\\DAiSEE\\Labels\\AllLabels.csv\")\n",
    "\n",
    "new_label_set = label_set.drop(columns=['Engagement', 'Confusion', 'Frustration'], axis=1)\n",
    "\n",
    "print(\"Unbalanced boredom dataset class distribution:\")\n",
    "print(new_label_set.shape)\n",
    "print(new_label_set['Boredom'].value_counts())\n",
    "print('-------------------------------------------s')\n",
    "\n",
    "\n",
    "# Balance the dataset by sampling an equal number of videos for each class in 'Boredom'\n",
    "# The size is limited to the smallest class size\n",
    "min_class_size = 330\n",
    "balanced_data = new_label_set.groupby('Boredom', group_keys=False).apply(\n",
    "    lambda x: x.sample(min_class_size, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Check the new balanced distribution\n",
    "print(\"Balanced dataset class distribution:\")\n",
    "print(balanced_data['Boredom'].value_counts())\n",
    "\n",
    "print('-------------------------------------------')\n",
    "\n",
    "# Further balance: Ensure all persons in the dataset have an equal number of videos (10 videos per person)\n",
    "# Extract 'person_id' from the 'ClipID' column\n",
    "balanced_data['person_id'] = balanced_data['ClipID'].str[:6]\n",
    "balanced_data = balanced_data.groupby('person_id', group_keys=False).apply(\n",
    "    lambda x: x.sample(10, random_state=42) if len(x) >= 10 else None\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Check the updated counts\n",
    "person_counts = Counter(balanced_data['person_id'])\n",
    "print(dict(person_counts))\n",
    "\n",
    "print(\"\\nLength of the updated dataset:\")\n",
    "print(len(balanced_data))\n",
    "\n",
    "\n",
    "# Define the split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split the data into training and temp (for validation and testing)\n",
    "train_data, temp_data = train_test_split(\n",
    "    balanced_data, test_size=(1 - train_ratio), random_state=42, stratify=balanced_data['Boredom']\n",
    ")\n",
    "\n",
    "# Further split the temp data into validation and testing\n",
    "val_data, test_data = train_test_split(\n",
    "    temp_data, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42, stratify=temp_data['Boredom']\n",
    ")\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "print(\"Test set size:\", len(test_data))\n",
    "\n",
    "# Save each split as a CSV file\n",
    "train_data.to_csv(\"train_labels.csv\", index=False)\n",
    "val_data.to_csv(\"val_labels.csv\", index=False)\n",
    "test_data.to_csv(\"test_labels.csv\", index=False)\n",
    "\n",
    "print(\"Train, validation, and test splits saved as CSV files.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To simplify training without a GPU, weâ€™ll use a smaller subset of the dataset. This reduces computational load, speeds up experimentation, and lets us validate the pipeline before scaling to the full dataset. To put it simply, we will create a new dataset out of the current one we have.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dataset class distribution:\n",
      "Boredom\n",
      "0    25\n",
      "1    25\n",
      "2    25\n",
      "3    25\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length of the reduced dataset:\n",
      "100\n",
      "{'500044': 2, '110006': 1, '210061': 3, '310072': 1, '500095': 1, '110001': 1, '310074': 4, '350361': 2, '110007': 2, '410020': 2, '510038': 1, '110015': 4, '410030': 3, '882654': 2, '310079': 2, '567496': 4, '500067': 3, '510046': 2, '310062': 2, '510035': 2, '210059': 1, '459999': 1, '310070': 1, '410026': 4, '210052': 1, '410032': 2, '202614': 3, '181374': 2, '310077': 1, '205601': 1, '210053': 2, '414081': 1, '410029': 2, '200050': 4, '334463': 1, '210058': 2, '826412': 1, '410024': 2, '410028': 2, '510040': 1, '110014': 1, '310082': 3, '110017': 1, '411021': 2, '310076': 1, '556463': 1, '110012': 1, '310075': 2, '400018': 1, '411031': 1, '410019': 1, '240846': 1, '210060': 1, '111003': 1, '210055': 1, '510034': 1, '410025': 1}\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "# Target size per class\n",
    "videos_per_class = 25\n",
    "\n",
    "# Downsample each class\n",
    "small_dataset = balanced_data.groupby('Boredom', group_keys=False).apply(\n",
    "    lambda x: x.sample(videos_per_class, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Check the reduced dataset\n",
    "print(\"Reduced dataset class distribution:\")\n",
    "print(small_dataset['Boredom'].value_counts())\n",
    "\n",
    "print(\"\\nLength of the reduced dataset:\")\n",
    "print(len(small_dataset))\n",
    "\n",
    "person_counts = Counter(small_dataset['person_id'])\n",
    "print(dict(person_counts))\n",
    "print(len(person_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dataset class distribution:\n",
      "Boredom\n",
      "0    32\n",
      "1    32\n",
      "2    32\n",
      "3    32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Length of the reduced dataset:\n",
      "128\n",
      "{'240846': 2, '210060': 3, '210059': 2, '310079': 3, '110012': 3, '210055': 2, '826382': 3, '882654': 2, '110017': 2, '310078': 3, '181374': 2, '210057': 3, '410020': 2, '510035': 3, '110001': 3, '400018': 3, '310072': 1, '510046': 3, '310076': 3, '500044': 3, '500095': 2, '334463': 3, '410028': 2, '342227': 3, '310074': 2, '110007': 3, '205601': 3, '210052': 3, '410026': 3, '110015': 3, '410032': 3, '410024': 3, '350361': 2, '556463': 3, '400033': 3, '410029': 2, '400030': 2, '111003': 2, '310075': 3, '210058': 3, '500039': 3, '110014': 3, '500067': 1, '411031': 3, '200050': 3, '826412': 2, '510034': 2, '410030': 3, '410019': 2, '411021': 2}\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Target size per person\n",
    "videos_per_person = 3\n",
    "\n",
    "# Downsample to ensure diversity: max 3 videos per person\n",
    "small_dataset = balanced_data.groupby('person_id', group_keys=False).apply(\n",
    "    lambda x: x.sample(videos_per_person, random_state=42) if len(x) >= videos_per_person else None\n",
    ").dropna().reset_index(drop=True)\n",
    "\n",
    "# Ensure class balance: Equal number of videos for each boredom level\n",
    "min_samples_per_class = small_dataset['Boredom'].value_counts().min()\n",
    "smalL_balanced_dataset = small_dataset.groupby('Boredom', group_keys=False).apply(\n",
    "    lambda x: x.sample(min_samples_per_class, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Check distribution\n",
    "print(\"Reduced dataset class distribution:\")\n",
    "print(smalL_balanced_dataset['Boredom'].value_counts())\n",
    "\n",
    "print(\"\\nLength of the reduced dataset:\")\n",
    "print(len(smalL_balanced_dataset))\n",
    "\n",
    "\n",
    "person_counts = Counter(smalL_balanced_dataset['person_id'])\n",
    "print(dict(person_counts))\n",
    "print(len(person_counts))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 89\n",
      "Validation set size: 26\n",
      "Test set size: 13\n",
      "Train, validation, and test splits saved as CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Define the split ratios\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split the data into training and temp (for validation and testing)\n",
    "train_data, temp_data = train_test_split(\n",
    "    smalL_balanced_dataset, test_size=(1 - train_ratio), random_state=42, stratify=smalL_balanced_dataset['Boredom']\n",
    ")\n",
    "\n",
    "# Further split the temp data into validation and testing\n",
    "val_data, test_data = train_test_split(\n",
    "    temp_data, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42, stratify=temp_data['Boredom']\n",
    ")\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(\"Train set size:\", len(train_data))\n",
    "print(\"Validation set size:\", len(val_data))\n",
    "print(\"Test set size:\", len(test_data))\n",
    "\n",
    "# Save each split as a CSV file\n",
    "train_data.to_csv(\"train_labels_small.csv\", index=False)\n",
    "val_data.to_csv(\"val_labels_small.csv\", index=False)\n",
    "test_data.to_csv(\"test_labels_small.csv\", index=False)\n",
    "\n",
    "print(\"Train, validation, and test splits saved as CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Feature Set into Train, Test, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:07<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected frames from videos successfully copied to 'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\feature_set_small\\training'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [00:02<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected frames from videos successfully copied to 'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\feature_set_small\\validation'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 46.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected frames from videos successfully copied to 'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\feature_set_small\\testing'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def build_clip_map(root_dirs):\n",
    "    \"\"\"\n",
    "    Walks through the dataset directory and maps each clip_id to its corresponding folder path.\n",
    "    \"\"\"\n",
    "    clip_map = {} # Putting all folder names in a hashset as it will take O(1) lookup time\n",
    "    for split, root_path in root_dirs.items():\n",
    "        for root, dirs, _ in os.walk(root_path):\n",
    "            for dir_name in dirs:\n",
    "                clip_map[dir_name] = os.path.join(root, dir_name)\n",
    "    return clip_map\n",
    "\n",
    "def process_small_dataset(label_csv, clip_map, output_dir, num_frames=10, step=30):\n",
    "    \"\"\"\n",
    "    Process the small dataset to organize clips and frames into structured folders.\n",
    "    \n",
    "    Args:\n",
    "        label_csv (str): Path to the CSV file containing clip IDs for the dataset.\n",
    "        clip_map (dict): Map of clip_id to full folder path.\n",
    "        output_dir (str): Directory to save the processed dataset.\n",
    "        num_frames (int): Number of frames to select per video.\n",
    "        step (int): Step size for frame selection.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_videos = 0\n",
    "    labels = pd.read_csv(label_csv)\n",
    "    for _, row in tqdm(labels.iterrows(), total=len(labels), desc=\"Processing videos\"):\n",
    "        clip_id = row['ClipID']\n",
    "        clip_source_path = clip_map.get(clip_id.split('.')[0])  # Remove file extension\n",
    "        \n",
    "        if not clip_source_path:\n",
    "            print(f\"Warning: Clip {clip_id} not found in original dataset.\")\n",
    "            continue\n",
    "\n",
    "        # Create target folder for the clip\n",
    "        target_clip_folder = os.path.join(output_dir, f\"{clip_id}_frames\")\n",
    "        select_every_nth_frames(clip_source_path, target_clip_folder, num_frames, step)\n",
    "\n",
    "    print(f\"\\nSelected frames from videos successfully copied to '{output_dir}'!\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def select_every_nth_frames(source_path, target_path, num_frames, step=30):\n",
    "    \"\"\"\n",
    "    Select every nth frame from a video folder and copy to target folder. In our situation that would be every 30th frame.\n",
    "    \n",
    "    Args:\n",
    "        source_path (str): Path to the source video frames.\n",
    "        target_path (str): Path to save the selected frames.\n",
    "        num_frames (int): Number of frames to select.\n",
    "        step (int): Step size for frame selection.\n",
    "    \"\"\"\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    frame_files = sorted(os.listdir(source_path))[::step][:num_frames]\n",
    "    for frame_file in frame_files:\n",
    "        shutil.copy(os.path.join(source_path, frame_file), target_path)\n",
    "\n",
    "\n",
    "small_train_labels = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\label_set_small\\train_labels_small.csv'\n",
    "small_val_labels = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\label_set_small\\val_labels_small.csv'\n",
    "small_test_labels = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\label_set_small\\test_labels_small.csv'\n",
    "\n",
    "small_train_features_dir = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\feature_set_small\\training'\n",
    "small_val_features_dir = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\feature_set_small\\validation'\n",
    "small_test_features_dir = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\new_dataset_small\\feature_set_small\\testing'\n",
    "\n",
    "original_dataset_dirs = {\n",
    "    'Test': 'C:\\\\Users\\\\ahmad\\\\Desktop\\\\EngagementML\\\\DAiSEE\\\\DataSet\\\\Test',\n",
    "    'Train': 'C:\\\\Users\\\\ahmad\\\\Desktop\\\\EngagementML\\\\DAiSEE\\\\DataSet\\\\Train',\n",
    "    'Validation': 'C:\\\\Users\\\\ahmad\\\\Desktop\\\\EngagementML\\\\DAiSEE\\\\DataSet\\\\Validation'\n",
    "}\n",
    "\n",
    "# Build clip map\n",
    "clip_map = build_clip_map(original_dataset_dirs)\n",
    "\n",
    "# Process each small subset\n",
    "process_small_dataset(small_train_labels, clip_map, small_train_features_dir)\n",
    "process_small_dataset(small_val_labels, clip_map, small_val_features_dir)\n",
    "process_small_dataset(small_test_labels, clip_map, small_test_features_dir)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
