{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Script That Converts Image into a normalized grayscale tensor, with features extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0118,  0.0144,  0.0092,  ..., -0.4353, -0.1163, -0.0588],\n",
       "         [ 0.0039, -0.0222, -0.0222,  ..., -0.5399, -0.2993, -0.0850],\n",
       "         [-0.0013, -0.0118, -0.0170,  ..., -0.6288, -0.4824, -0.0954],\n",
       "         ...,\n",
       "         [-0.6497, -0.7542, -0.7908,  ..., -0.7961, -0.7647, -0.7438],\n",
       "         [-0.7961, -0.7961, -0.8065,  ..., -0.7961, -0.7595, -0.7281],\n",
       "         [-0.8327, -0.7961, -0.8065,  ..., -0.8013, -0.7647, -0.7281]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load OpenCV DNN\n",
    "model_path = \"C:/Users/ahmad/Desktop/EngagementML/opencv-dnn/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "config_path = \"C:/Users/ahmad/Desktop/EngagementML/opencv-dnn/deploy.prototxt\"\n",
    "\n",
    "\n",
    "# Define a PyTorch transform for grayscale conversion\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to 1-channel grayscale\n",
    "    transforms.ToTensor(),                         # Convert to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.75], std=[0.75])   # Normalize: shift and scale pixel values\n",
    "])\n",
    "\n",
    "\n",
    "def preprocess_frame(image_path, face_net, target_size=(80, 80)):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Could not read image {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Prepare the image for the DNN\n",
    "    blob = cv2.dnn.blobFromImage(image, scalefactor=1.0, size=(300, 300),\n",
    "                                 mean=(104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "    face_net.setInput(blob)\n",
    "    detections = face_net.forward()\n",
    "\n",
    "    (h, w) = image.shape[:2]\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:  # Confidence threshold\n",
    "            # Get the bounding box\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (x, y, x1, y1) = box.astype(\"int\")\n",
    "\n",
    "            # Ensure the bounding box is within the image dimensions\n",
    "            x, y, x1, y1 = max(0, x), max(0, y), min(w, x1), min(h, y1)\n",
    "\n",
    "            # Crop the face\n",
    "            cropped_face = image[y:y1, x:x1]\n",
    "\n",
    "            resized_face = cv2.resize(cropped_face, target_size)\n",
    "\n",
    "            # Convert the resized face to a PIL image\n",
    "            pil_face = Image.fromarray(cv2.cvtColor(resized_face, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            transformed_face_tensor = transform(pil_face)\n",
    "\n",
    "            return transformed_face_tensor\n",
    "\n",
    "\n",
    "# Load the pre-trained DNN model\n",
    "face_net = cv2.dnn.readNetFromCaffe(config_path, model_path)\n",
    "\n",
    "\n",
    "img_path = r'C:\\Users\\ahmad\\Desktop\\EngagementML\\resized_faces\\51004210183.jpg_face0.jpg'\n",
    "\n",
    "preprocess_frame(img_path, face_net, target_size=(80, 80))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
